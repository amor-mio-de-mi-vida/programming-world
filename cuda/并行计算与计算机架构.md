# cuda编程



最近在学习CUDA编程，将最近看到的一些资源进行汇总。

书籍和文档

1. 英伟达CUDA C++编程入门
   NVIDIA CUDA C++ Programming Guide
   https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html
   官方的文档我只是浏览了一遍，写的很扎实，把一些基本的概念都讲清楚了，但是因为是英文，可能对于有些同学有障碍。
   当然也存在一些解读，大致上浏览了一遍，讲的还是比较笼统，详细部分还是需要看官方的文档：
   https://zhuanlan.zhihu.com/p/53773183
2. 英伟达CUDA C++最佳实践
   CUDA C++ Best Practices Guide
   https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html
   这个是面对实际应用场景而出的一个API，主要关注与怎么解决性能瓶颈，在内容上我看到有纹理内存，zeroCopy、控制流等，大致是在如何更快地优化CUDA上的运行性能。
3. CUDA by Example
   http://www.mat.unimi.it/users/sansotte/cuda/CUDA_by_Example.pdf
   https://developer.download.nvidia.com/books/cuda-by-example/cuda-by-example-sample.pdf
   作者曾是nvidia的高级工程师，现在在google，差不多是前面两个API文档的总结。有中文版，名为《GPU高性能编程-CUDA实战》，有个别翻译错误，整体还不错。
4. CUDA C编程权威指南
   这么经典的书就不用我多说了，英文原版叫《Professional CUDA C Programming》：
   http://www.hds.bme.hu/~fhegedus/C++/Professional CUDA C Programming.pdf

个人博客

谭升的博客
https://face2ai.com/program-blog/#GPU编程（CUDA）
对很多cuda基本概念进行了总结，讲的还不错，有对应的开源代码。
https://github.com/Tony-Tan/CUDA_Freshman

CUDA编程入门系列
https://zhuanlan.zhihu.com/p/97044592
有6篇，讲了一步步优化的方法，入门还是可以的。

CUDA编程系列
https://blog.csdn.net/sunmc1204953974/article/details/51000970
稍微有点老，不过还是有很多东西可以快速过一遍。

开源代码

DeepSpeed
https://github.com/microsoft/DeepSpeed
微软开源的深度学习分布式训练加速引擎。





## 并行计算与计算机架构

计算机架构

- 单指令单数据SISD(传统串行计算机，386)
- 单指令多数据SIMD(并行架构，比如向量机，所有核心指令唯一，但是数据不同，现在CPU基本都有这类的向量指令)
- 多指令单数据MISD(少见，多个指令围殴一个数据)
- 多指令多数据MIMD(并行架构，多核心，多指令，异步处理多个数据流，从而实现空间上的并行，MIMD多数情况下包含SIMD，就是MIMD有很多计算核，计算核支持SIMD)



CPU和GPU之间通过PCIE总线连接，用于传递指令和数据，这部分也是后面要讨论的性能瓶颈之一。一个异构应用包含两种以上架构。主机代码在主机端运行，被编译成主机架构的机器码，设备端的在设备上执行，被编译成设备架构的机器码，所以主机端的机器码和设备端的机器码是隔离的，自己执行自己的，没办法交换执行。主机端代码主要是控制设备，完成数据传输等控制类工作，设备端主要的任务就是计算。

**cuda :一种异构计算平台**

CUDA平台不是单单指软件或者硬件，而是建立在Nvidia GPU上的一整套平台，并扩展出多语言支持。

![image-20230618231058474](C:\Users\W\AppData\Roaming\Typora\typora-user-images\image-20230618231058474.png)

![image-20230618231123633](C:\Users\W\AppData\Roaming\Typora\typora-user-images\image-20230618231123633.png)

驱动API是低级的API， 使用相对困难，运行时API是高级API使用简单，其实现基于驱动API。这两种API是互斥的，也就是你只能用一个，两者之间的函数不可以混合调用，只能调用其中的一个库。



一个CUDA应用通常可以分解为两个部分，

- CPU主机端代码
- GPU设备端代码

CUDA nvcc编译器会自动分离你代码里面的不同部分，如图中主机代码用C写成，使用本地的C语言编译器编译，设备端代码，也就是核函数，用CUDA C编写，通过nvcc编译，链接阶段，在内核程序调用或者明显的GPU设备操作时，添加运行时库。

![image-20230618231518327](C:\Users\W\AppData\Roaming\Typora\typora-user-images\image-20230618231518327.png)

![image-20230618231533510](C:\Users\W\AppData\Roaming\Typora\typora-user-images\image-20230618231533510.png)

**Hello World**

```c
/*
*hello_world.cu
*/
#include<stdio.h>
__global__ void hello_world(void)
{
	printf("GPU: Hello world!\n");
}
int main(int argc, char **argv)
{
	printf("CPU: Hello world!\n");
	hello_world<<<1,10>>>();
	cudaDeviceReset();// if no this line, it cannot output hello world from gpu
	return 0;
}
```

`cudaDeviceReset();`

这句话如果没有，则不能正常的运行，因为这句话包含了隐式同步，GPU和CPU执行程序是异步的，核函数调用后立刻回到主机线程继续，而不管GPU端核函数是否执行完毕。

一般CUDA程序分成下面这些步骤：

- 分配GPU内存
- 拷贝内存到设备
- 调用CUDA内核函数来执行计算
- 把计算完成数据拷贝回主机端
- 内存销毁



CUDA中有两个模型是决定性能的：

- 内存层次结构
- 线程层次结构

CUDA C写核函数的时候我们只写一小段串行代码，但是这段代码被成千上万的线程执行，所有线程执行的代码都是相同的，CUDA编程模型提供了一个层次化的组织线程，直接影响GPU上的执行顺序。

CUDA抽象了硬件实现：

- 线程组的层次结构
- 内存的层次结构
- 障碍同步

NVIDIA为我们提供了：

- Nvidia Nsight集成开发环境
- CUDA-GDB 命令行调试器
- 性能分析可视化工具
- CUDA-MEMCHECK工具
- GPU设备管理工具



CUDA编程模型概述（一）

CUDA C是编译型语言，不是解释型语言，OpenCL有点类似于解释型语言，通过编译器和链接，给操作系统执行(操作系统包括GPU在内的系统)。

